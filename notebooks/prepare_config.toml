# Configuration for Preprocessing and Evaluation
# prepare_config.toml

[paths]
# the original test data is here:
batch_filepath = "gs://<my-butket-name>/evaluation_data/DSC_Rep_Sample.csv"
gcs_bucket_name = "<my-butket-name>"
evaluation_data = "evaluation_data/"

# The Docker run puts the data here
gcs_json_dir = "analysis_outputs/"
named_file = "gs://<my-butket-name>/analysis_outputs/20250620_153641_output.json"

# After running 'add_data_quality_flags', the helper columns will be written to here:
analysis_csv = "gs://<my-butket-name>/analysis_outputs/added_columns/flags_20250620_153641.csv"

# Merged file store:
merged_file = "gs://<my-butket-name>/analysis_outputs/merged_files/merged_flags_20250620_153641.csv"

merged_file_list = ["gs://<my-butket-name>/analysis_outputs/merged_files/merged_flags_20250620_153641.csv",
"gs://<my-butket-name>/analysis_outputs/merged_files/Jyl_2025-06-27_codability_gemini_1.5-flash.csv",
"gs://<my-butket-name>/analysis_outputs/merged_files/Jyl_2025-06-27_codability_gemini_2-flash.csv" ]
[parameters]
# Process only files created on or after this date (YYYYMMDD)
single_file = "True"
date_since = "20250710"

[json_keys]
unique_id = "unique_id"